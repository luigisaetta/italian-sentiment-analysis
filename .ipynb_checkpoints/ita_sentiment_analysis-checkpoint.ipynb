{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0bafdd",
   "metadata": {},
   "source": [
    "### Sentiment Analysis in Italian using Transformers\n",
    "\n",
    "based on Neuraly work:\n",
    "* see: https://huggingface.co/neuraly/bert-base-italian-cased-sentiment\n",
    "* https://medium.com/@a.bellini/leveraging-huggingfaces-transformers-for-cross-lingual-sentiment-analysis-acca1f4e9da6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b58b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn  \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2194f",
   "metadata": {},
   "source": [
    "### Python class\n",
    "\n",
    "I have encapsulated the code from the HF site of the model, with some semplification, in a Python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20e52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITASentimentAnalyzer:\n",
    "    # load the tokenizer and transformer\n",
    "    def __init__(self, MODEL_NAME):\n",
    "        \n",
    "        # for rounding\n",
    "        self.DEC_DIGITS = 4\n",
    "        \n",
    "        # name of HuggingFace model used\n",
    "        self.MODEL_NAME = MODEL_NAME\n",
    "        \n",
    "        print(\"Loading model...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.MODEL_NAME)\n",
    "        # Load the model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.MODEL_NAME)\n",
    "        \n",
    "        print(\"Model loading completed!\")\n",
    "    \n",
    "    # utility to get rid of tensor and round\n",
    "    def round(self, tens_val):\n",
    "        \n",
    "        return round(tens_val.item(), self.DEC_DIGITS)\n",
    "    \n",
    "    def compute_ids(self, input_sentence):\n",
    "        input_ids = self.tokenizer(input_sentence, add_special_tokens=True)['input_ids']\n",
    "        print(input_ids)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    #\n",
    "    # does the scoring on a single sentence a time\n",
    "    #\n",
    "    def score(self, input_sentence):\n",
    "        # encode the sentence and create the input tensor (in PyTorch format)\n",
    "        input_ids = self.tokenizer(input_sentence, add_special_tokens=True, return_tensors='pt')['input_ids']\n",
    "        \n",
    "        # output from tokenizer is already a tensor\n",
    "        \n",
    "        # Call the model and get the logits\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids)['logits']\n",
    "\n",
    "        # The model was trained with a Log Likelyhood + Softmax combined loss, hence to extract probabilities we need a softmax on top of the logits tensor\n",
    "        proba = nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "        # to remove the added dimension with squeeze\n",
    "        # proba is (negative, neutral, positive)\n",
    "        scores = proba.squeeze(0)\n",
    "        \n",
    "        # get rid of tensor and round and \n",
    "        # prepare the output json\n",
    "        \n",
    "        ret_vet = []\n",
    "        \n",
    "        for i, label in enumerate(['negative', 'neutral', 'positive']):\n",
    "            ret_vet.append({'label' : label, 'score' : self.round(scores[i])})\n",
    "        \n",
    "        return ret_vet\n",
    "    \n",
    "    def batch_predict(self, input_sentences):\n",
    "        # encode the sentence and create the input tensor\n",
    "        input_ids = self.tokenizer(input_sentences, add_special_tokens=True, padding=True)['input_ids']\n",
    "        \n",
    "        print(input_ids)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74cf479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loading completed!\n",
      "CPU times: user 827 ms, sys: 147 ms, total: 974 ms\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loading the model: pass the HF model name\n",
    "sent_analyzer = ITASentimentAnalyzer(\"neuraly/bert-base-italian-cased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a3ea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9716},\n",
       " {'label': 'neutral', 'score': 0.0181},\n",
       " {'label': 'positive', 'score': 0.0103}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = sent_analyzer.score(\"Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela\")\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1486f3",
   "metadata": {},
   "source": [
    "### test su un set di frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a42efac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E' un prodotto pessimo\n",
      "[{'label': 'negative', 'score': 0.9978}, {'label': 'neutral', 'score': 0.002}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "La sua organizzazione ha fornito un buon servizio alla clientela\n",
      "[{'label': 'negative', 'score': 0.0002}, {'label': 'neutral', 'score': 0.002}, {'label': 'positive', 'score': 0.9978}]\n",
      "\n",
      "La sua organizzazione non ha fornito un buon servizio alla clientela\n",
      "[{'label': 'negative', 'score': 0.9951}, {'label': 'neutral', 'score': 0.0046}, {'label': 'positive', 'score': 0.0003}]\n",
      "\n",
      "Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela\n",
      "[{'label': 'negative', 'score': 0.9716}, {'label': 'neutral', 'score': 0.0181}, {'label': 'positive', 'score': 0.0103}]\n",
      "\n",
      "Il prodotto non funziona, non comprero' più nulla dalla vostra azienda\n",
      "[{'label': 'negative', 'score': 0.9976}, {'label': 'neutral', 'score': 0.0023}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "Io penso che la sua organizzazione non abbia fornito un buon servizio alla clientela\n",
      "[{'label': 'negative', 'score': 0.9973}, {'label': 'neutral', 'score': 0.0025}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona?\n",
      "[{'label': 'negative', 'score': 0.0006}, {'label': 'neutral', 'score': 0.8939}, {'label': 'positive', 'score': 0.1055}]\n",
      "\n",
      "La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona\n",
      "[{'label': 'negative', 'score': 0.0004}, {'label': 'neutral', 'score': 0.0487}, {'label': 'positive', 'score': 0.9509}]\n",
      "\n",
      "La vostra organizzazione offre servizi pessimi\n",
      "[{'label': 'negative', 'score': 0.9852}, {'label': 'neutral', 'score': 0.0146}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "La vostra organizzazione offre servizi non adeguati\n",
      "[{'label': 'negative', 'score': 0.9593}, {'label': 'neutral', 'score': 0.0405}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "Sono molto soddisfatto del tuo lavoro\n",
      "[{'label': 'negative', 'score': 0.0002}, {'label': 'neutral', 'score': 0.0015}, {'label': 'positive', 'score': 0.9984}]\n",
      "\n",
      "non sono del tutto sicuro che il lavoro sia adeguato\n",
      "[{'label': 'negative', 'score': 0.6756}, {'label': 'neutral', 'score': 0.3186}, {'label': 'positive', 'score': 0.0058}]\n",
      "\n",
      "l'azienda dovrebbe offrire servizi migliori\n",
      "[{'label': 'negative', 'score': 0.0035}, {'label': 'neutral', 'score': 0.0057}, {'label': 'positive', 'score': 0.9908}]\n",
      "\n",
      "il supporto offerto dal customer care non è stato adeguato\n",
      "[{'label': 'negative', 'score': 0.9884}, {'label': 'neutral', 'score': 0.0114}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "il risultato è pessimo\n",
      "[{'label': 'negative', 'score': 0.9974}, {'label': 'neutral', 'score': 0.0025}, {'label': 'positive', 'score': 0.0002}]\n",
      "\n",
      "il Napoli ha giocato una partita ottima\n",
      "[{'label': 'negative', 'score': 0.0001}, {'label': 'neutral', 'score': 0.0134}, {'label': 'positive', 'score': 0.9865}]\n",
      "\n",
      "il lavoro dell'allenatore è stato modesto\n",
      "[{'label': 'negative', 'score': 0.0141}, {'label': 'neutral', 'score': 0.9705}, {'label': 'positive', 'score': 0.0154}]\n",
      "\n",
      "\n",
      "CPU times: user 2.69 s, sys: 44.6 ms, total: 2.73 s\n",
      "Wall time: 683 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_sentences = [\n",
    "    \"E' un prodotto pessimo\",\n",
    "    \"La sua organizzazione ha fornito un buon servizio alla clientela\",\n",
    "    \"La sua organizzazione non ha fornito un buon servizio alla clientela\",\n",
    "    \"Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela\",\n",
    "    \"Il prodotto non funziona, non comprero' più nulla dalla vostra azienda\",\n",
    "    \"Io penso che la sua organizzazione non abbia fornito un buon servizio alla clientela\",\n",
    "    \"La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona?\",\n",
    "    \"La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona\",\n",
    "    \"La vostra organizzazione offre servizi pessimi\",\n",
    "    \"La vostra organizzazione offre servizi non adeguati\",\n",
    "    \"Sono molto soddisfatto del tuo lavoro\",\n",
    "    \"non sono del tutto sicuro che il lavoro sia adeguato\",\n",
    "    \"l'azienda dovrebbe offrire servizi migliori\",\n",
    "    \"il supporto offerto dal customer care non è stato adeguato\",\n",
    "    \"il risultato è pessimo\",\n",
    "    \"il Napoli ha giocato una partita ottima\",\n",
    "    \"il lavoro dell'allenatore è stato modesto\"\n",
    "]\n",
    "\n",
    "\n",
    "# sent_analyzer = ITASentimentAnalyzer()\n",
    "for sentence in input_sentences:\n",
    "        scores = sent_analyzer.score(sentence)\n",
    "    \n",
    "        print(sentence)\n",
    "        print(scores)\n",
    "        print()\n",
    "            \n",
    "# formatting\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de184436",
   "metadata": {},
   "source": [
    "### next step: Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e46e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_p37_cpu_v2]",
   "language": "python",
   "name": "conda-env-nlp_p37_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
