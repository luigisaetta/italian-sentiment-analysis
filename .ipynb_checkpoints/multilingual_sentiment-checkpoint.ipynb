{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c360c64",
   "metadata": {},
   "source": [
    "### Multi-lingual model based on Transformer for Sentiment Analysis\n",
    "\n",
    "* Conda env used: **Natural Language Processing for CPU Python 3.7**\n",
    "* the model is based on a pre-trained transformer available from **Hugging Face Hub**: \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "* if a GPU is available, the model does inference on GPU (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d693824",
   "metadata": {},
   "source": [
    "**Sentiment Analysis**: we want to analyze a text and establish if the sentiment expressed is positive, negative or neutral.\n",
    "\n",
    "In the case of the transformer used here, it is used a scale with a **number of stars** ranging from **1** (very negative) to **5** (highly positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbcb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "# HuggingFace transformers (availale in OCI DS conda nlp env)\n",
    "# see: https://github.com/huggingface/transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# from my Python file\n",
    "from sentiment_analyzers import MultiLanguageSentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab48d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loading completed!\n",
      "CPU times: user 5.36 s, sys: 1.56 s, total: 6.93 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loading the model: pass the HF model name\n",
    "MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# labels are dependent on the used model , see HF documentation\n",
    "sent_analyzer = MultiLanguageSentimentAnalyzer(\n",
    "    MODEL_NAME, labels=[\"1 star\", \"2 star\", \"3 star\", \"4 star\", \"5 star\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f2451",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d829e5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is using GPU?\n",
    "sent_analyzer.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8affd95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il servizio offerto alla clientela è ottimo\n",
      "1 star: 0.0056|2 star: 0.0059|3 star: 0.0518|4 star: 0.323|5 star: 0.6137|\n",
      "\n",
      "CPU times: user 144 ms, sys: 26.6 ms, total: 170 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentence = \"Il servizio offerto alla clientela è ottimo\"\n",
    "scores = sent_analyzer.score(sentence)\n",
    "\n",
    "print(sentence)\n",
    "print(sent_analyzer.format_scores(scores))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913b637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The service you have offered to your customers is really good\n",
      "1 star: 0.0031|2 star: 0.0043|3 star: 0.0572|4 star: 0.4137|5 star: 0.5217|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The service you have offered to your customers is really good\"\n",
    "\n",
    "scores = sent_analyzer.score(sentence)\n",
    "\n",
    "print(sentence)\n",
    "print(sent_analyzer.format_scores(scores))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d6f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences for tests\n",
    "input_sentences = [\n",
    "    \"Noi pensiamo che questa riunione sia stata proficua\",\n",
    "    \"Noi pensiamo che questa riunione sia stata molto proficua\",\n",
    "    \"The service offered to your customers is really good\",\n",
    "    \"E' un prodotto pessimo\",\n",
    "    \"La sua organizzazione ha fornito un buon servizio alla clientela\",\n",
    "    \"La sua organizzazione non ha fornito un buon servizio alla clientela\",\n",
    "    \"Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela\",\n",
    "    \"Il prodotto non funziona, non comprero' più nulla dalla vostra azienda\",\n",
    "    \"Io penso che la sua organizzazione non abbia fornito un buon servizio alla clientela\",\n",
    "    \"La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona?\",\n",
    "    \"La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona\",\n",
    "    \"La vostra organizzazione offre servizi pessimi\",\n",
    "    \"La vostra organizzazione offre servizi non adeguati\",\n",
    "    \"Sono molto soddisfatto del tuo lavoro\",\n",
    "    \"non sono del tutto sicuro che il lavoro sia adeguato\",\n",
    "    \"l'azienda dovrebbe offrire servizi migliori\",\n",
    "    \"il supporto offerto dal customer care non è stato adeguato\",\n",
    "    \"il risultato è pessimo\",\n",
    "    \"il Napoli ha giocato una partita decente\",\n",
    "    \"il lavoro dell'allenatore è stato modesto\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acdac1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Noi pensiamo che questa riunione sia stata proficua\n",
      "1 star: 0.0614|2 star: 0.0941|3 star: 0.3085|4 star: 0.2887|5 star: 0.2473|\n",
      "\n",
      "2. The service offered to your customers is really good\n",
      "1 star: 0.004|2 star: 0.0051|3 star: 0.0578|4 star: 0.4196|5 star: 0.5135|\n",
      "\n",
      "3. E' un prodotto pessimo\n",
      "1 star: 0.9365|2 star: 0.0558|3 star: 0.0063|4 star: 0.0008|5 star: 0.0006|\n",
      "\n",
      "4. La sua organizzazione ha fornito un buon servizio alla clientela\n",
      "1 star: 0.0041|2 star: 0.0072|3 star: 0.1284|4 star: 0.5368|5 star: 0.3235|\n",
      "\n",
      "5. La sua organizzazione non ha fornito un buon servizio alla clientela\n",
      "1 star: 0.2703|2 star: 0.4699|3 star: 0.2328|4 star: 0.0228|5 star: 0.0042|\n",
      "\n",
      "6. Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela\n",
      "1 star: 0.0336|2 star: 0.0579|3 star: 0.2817|4 star: 0.4109|5 star: 0.2159|\n",
      "\n",
      "7. Il prodotto non funziona, non comprero' più nulla dalla vostra azienda\n",
      "1 star: 0.9054|2 star: 0.0825|3 star: 0.0105|4 star: 0.0009|5 star: 0.0006|\n",
      "\n",
      "8. Io penso che la sua organizzazione non abbia fornito un buon servizio alla clientela\n",
      "1 star: 0.304|2 star: 0.4361|3 star: 0.2269|4 star: 0.0261|5 star: 0.0068|\n",
      "\n",
      "9. La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona?\n",
      "1 star: 0.1193|2 star: 0.2377|3 star: 0.3919|4 star: 0.1849|5 star: 0.0662|\n",
      "\n",
      "10. La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona\n",
      "1 star: 0.0058|2 star: 0.0141|3 star: 0.197|4 star: 0.5233|5 star: 0.2598|\n",
      "\n",
      "11. La vostra organizzazione offre servizi pessimi\n",
      "1 star: 0.806|2 star: 0.1544|3 star: 0.0321|4 star: 0.0048|5 star: 0.0027|\n",
      "\n",
      "12. La vostra organizzazione offre servizi non adeguati\n",
      "1 star: 0.433|2 star: 0.3875|3 star: 0.152|4 star: 0.0202|5 star: 0.0073|\n",
      "\n",
      "13. Sono molto soddisfatto del tuo lavoro\n",
      "1 star: 0.0022|2 star: 0.0024|3 star: 0.0228|4 star: 0.2904|5 star: 0.6822|\n",
      "\n",
      "14. non sono del tutto sicuro che il lavoro sia adeguato\n",
      "1 star: 0.0812|2 star: 0.4218|3 star: 0.4576|4 star: 0.0351|5 star: 0.0044|\n",
      "\n",
      "15. l'azienda dovrebbe offrire servizi migliori\n",
      "1 star: 0.1404|2 star: 0.2842|3 star: 0.3919|4 star: 0.1293|5 star: 0.0542|\n",
      "\n",
      "16. il supporto offerto dal customer care non è stato adeguato\n",
      "1 star: 0.3425|2 star: 0.4247|3 star: 0.2104|4 star: 0.0188|5 star: 0.0037|\n",
      "\n",
      "17. il risultato è pessimo\n",
      "1 star: 0.7333|2 star: 0.2177|3 star: 0.0447|4 star: 0.0034|5 star: 0.001|\n",
      "\n",
      "18. il Napoli ha giocato una partita decente\n",
      "1 star: 0.0261|2 star: 0.0901|3 star: 0.5554|4 star: 0.2638|5 star: 0.0645|\n",
      "\n",
      "19. il lavoro dell'allenatore è stato modesto\n",
      "1 star: 0.1189|2 star: 0.3707|3 star: 0.4305|4 star: 0.066|5 star: 0.0139|\n",
      "\n",
      "\n",
      "CPU times: user 176 ms, sys: 3.14 ms, total: 179 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# here we do inference one sentence a time (SLOWER)\n",
    "\n",
    "# object already instantiated\n",
    "\n",
    "for i, sentence in enumerate(input_sentences):\n",
    "\n",
    "    #\n",
    "    # here I do the scoring on a single sentence\n",
    "    #\n",
    "    scores = sent_analyzer.score(sentence)\n",
    "\n",
    "    # scores is a dict of []\n",
    "\n",
    "    print(f\"{i+1}. {sentence}\")\n",
    "    print(sent_analyzer.format_scores(scores))\n",
    "    print()\n",
    "\n",
    "# formatting\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f7168",
   "metadata": {},
   "source": [
    "### Test batch scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d45320b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Noi pensiamo che questa riunione sia stata proficua. Stelle: 3\n",
      "2. Noi pensiamo che questa riunione sia stata molto proficua. Stelle: 5\n",
      "3. The service offered to your customers is really good. Stelle: 5\n",
      "4. E' un prodotto pessimo. Stelle: 1\n",
      "5. La sua organizzazione ha fornito un buon servizio alla clientela. Stelle: 4\n",
      "6. La sua organizzazione non ha fornito un buon servizio alla clientela. Stelle: 2\n",
      "7. Non credo che la sua organizzazione abbia fornito un buon servizio alla clientela. Stelle: 4\n",
      "8. Il prodotto non funziona, non comprero' più nulla dalla vostra azienda. Stelle: 1\n",
      "9. Io penso che la sua organizzazione non abbia fornito un buon servizio alla clientela. Stelle: 2\n",
      "10. La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona?. Stelle: 3\n",
      "11. La gestione da parte della Regione Lazio della complessa macchina dei vaccini è stata buona. Stelle: 4\n",
      "12. La vostra organizzazione offre servizi pessimi. Stelle: 1\n",
      "13. La vostra organizzazione offre servizi non adeguati. Stelle: 1\n",
      "14. Sono molto soddisfatto del tuo lavoro. Stelle: 5\n",
      "15. non sono del tutto sicuro che il lavoro sia adeguato. Stelle: 3\n",
      "16. l'azienda dovrebbe offrire servizi migliori. Stelle: 3\n",
      "17. il supporto offerto dal customer care non è stato adeguato. Stelle: 2\n",
      "18. il risultato è pessimo. Stelle: 1\n",
      "19. il Napoli ha giocato una partita decente. Stelle: 3\n",
      "20. il lavoro dell'allenatore è stato modesto. Stelle: 3\n",
      "\n",
      "CPU times: user 31.5 ms, sys: 12.1 ms, total: 43.6 ms\n",
      "Wall time: 19.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# here we do batch scoring (faster)\n",
    "scores = sent_analyzer.batch_score(input_sentences)\n",
    "\n",
    "# Instead of a tensor I want the numpy vector\n",
    "stars = np.argmax(scores.numpy(), axis=-1)\n",
    "\n",
    "for i, (sentence, star) in enumerate(zip(input_sentences, stars)):\n",
    "    print(f\"{i+1}. {sentence}. Stelle: {star+1}\")\n",
    "    \n",
    "# for formatting only\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1b275",
   "metadata": {},
   "source": [
    "### custom test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57901135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E' un prodotto pessimo\n",
      "[{'label': '1 star', 'score': 0.9365}, {'label': '2 star', 'score': 0.0558}, {'label': '3 star', 'score': 0.0063}, {'label': '4 star', 'score': 0.0008}, {'label': '5 star', 'score': 0.0006}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"E' un prodotto pessimo\"\n",
    "\n",
    "print(sentence)\n",
    "print(sent_analyzer.score(sentence))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f8d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_p37_gpu_v2]",
   "language": "python",
   "name": "conda-env-nlp_p37_gpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
